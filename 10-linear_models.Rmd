#  Проверка линейной свзяи {#stats_criteria_linear} 

До этого мы рассматривали виды статистического анализа, когда нужно было сравнить средние значения в нескольких группах. Зависимая переменная всегда была количественная (ее среднее значение по группам мы и сравнивали), а независимая -- категориальная, принимала конечное число значений, и каждое ее значение -- отдельный уровень НП, отдельная группа.

Теперь мы переходим к статистическим критериям, которые используются, когда обе переменные, и ЗП, и НП -- количественные.
```{r, eval=TRUE, echo = FALSE, message = FALSE}
library(tidyverse)
library(kableExtra)
library(viridis)
studens_mat <- read_csv("student-mat.csv") %>% 
  rename_with(., ~ paste0(., "_mat"), .cols = c(absences, paid, G1, G2, G3)) -> studens_mat 
studens_por <- read_csv("student-por.csv") %>% 
  rename_with(., ~ paste0(., "_por"), .cols = c(absences, paid, G1, G2, G3)) -> studens_por
studens_mat %>% 
  full_join(studens_por, by = c("school","sex","age","address","famsize","Pstatus","Medu","Fedu",
                             "Mjob","Fjob","reason", "guardian", "traveltime","studytime", "failures", "schoolsup", "famsup",
                             "activities", "nursery", "higher", "internet", "romantic", "famrel", "freetime", "goout", 
                             "Dalc", "Walc", "health")) -> students 

students %>% 
  mutate("student" = paste0("id", row_number()), .before = "school")  %>% 
  drop_na() %>% 
  mutate(G_mat = rowMeans(dplyr::select(., c(G1_mat, G2_mat, G3_mat))),
         G_por = rowMeans(dplyr::select(., c(G1_por, G2_por, G3_por)))) %>% 
  mutate(absences_mat_groups = ifelse(absences_mat <=5, "less", ifelse(absences_mat <=15, "middle", "more"))) %>% 
  mutate(absences_por_groups = ifelse(absences_por <=5, "less", ifelse(absences_por <=15, "middle", "more"))) -> students
```

## Линейная регрессия 

Линейная регрессия -- метод анализа, ...

Линейная регрессия -- это ровно та же известная нам ANOVA, только если заменить категориальные НП на количественные!

### Коэффициенты регрессии

Уравнение регрессионной прямой:
<p align="center">$y = b_o + b_1x$ </p>

<p align="center"> 
```{r eval=TRUE, echo = FALSE, message = FALSE, fig.align = 'center', out.width="70%"}
knitr::include_graphics("docs/images/anova_SS.jpg")
```
</p>

<p align="center"> 
```{r eval=TRUE, echo = FALSE, message = FALSE, fig.align = 'center', out.width="70%"}
knitr::include_graphics("docs/images/lm_errors.jpeg")
```
</p>



Естьнесколько формул для вычисления коэффициентов линейной регрессии, но все они взаимовычисляемы. Вручную считать мы их не будем, поэтому что важно запомнить:

* Коэффициент $b_1$ отвечает на наклон прямой **(slope)**
* Коэффициент $b_0$ отвечает за смещение прямой вдоль оси y **(intercept)**
* При подсчете коэффициентов первым высчитывается $b_1$, и он зависит от величины вариативности данных по переменным x и y (стандартных отклонений или дисперсий) и **в случае равной вариативности является коэффициентом корреляции** $r_{xy}$

<p align="center">$b_{1_{xy}} = \frac{sd_y}{sd_x} r_{xy} $</p>

<p align="center">$b_o = \bar y -b_{1_{xy}}\bar x $</p>

Коэффициенты считаются таким образом, чтобы сумма квадратов остатков была минимальна. Это называется **методом наименьших квадратов**.

### Регрессионный анализ (тестирование коэффициентов регрессии)

Нулевая и альтернативная гипотезы:

<p align="center">$H_0$: $b_{1_{xy}} = 0$ </p>
<p align="center">$H_1$: $b_{1_{xy}} \neq 0$ </p>

### Допущения для регрессионного анализа

(ЗП и НП измерены в количественной или порядковой шкале)

1. Распределение НП по ЗП линейно -- то есть нет выборосов, нет картины нелинейной взаимосвязи или скоплений данных в разных местах.
2. Остатки (residuals) распределены нормально -- все то же самое, как [здесь](#param_nonparam), только для остатков
3. Остатки (residuals) варьируются примерно одинаково вдоль всей прямой (гомоскедастичность)
https://gallery.shinyapps.io/slr_diag/

### Расчет регрессионного анализа

```{r, eval=TRUE}
model_Gmat <- lm(students$G_mat ~ students$absences_mat)
summary(model_Gmat)
```

## Корреляционный анализ

**Корреляция** -- это связь между переменными.

Корреляция -- это, по сути, то же самое, что и линейная регрессия с одним фактором.

Чтобы вывести ее формулу и смысл, познакомимся с понятием ковариации.

**Ко-вариация (co-variance)** -- это мера со-изменчивость данных, показатель того, как наблюдения по переменным меняются друг относительно друга.

<p align="center"> 
```{r eval=TRUE, echo = FALSE, message = FALSE, fig.align = 'center', out.width="70%"}
knitr::include_graphics("docs/images/correlation.jpeg")
```
Картинка [отсюда](https://angelgardt.github.io/SFDA2022/book/twoway-anova.html#factor_interaction) </p>

<p align="center"> $\text{cov}(x,y)=\frac{\sum_{i=1}^n (x_i - \bar x) (y_i - \bar y )}{n-1}$</p>

**Коэффициент корреляции** -- это показатель силы и направления связи между переменными. По сути это ковариация переменных, но взвешенная на стандартные отклонения этих переменных. Это сделано для того, чтобы стандартизовать коэффициент, уйти от абсолютных значений к относительным и расположить этот коэффицент в границах [-1;1]. Для коэффициента корреляции Пирсена:

<p align="center"> $\text{corr}(x,y) = r_{xy} = \frac{\text{cov(x, y)}}{sd_x sd_y} = \frac{\sum_{i=1}^n (x_i - \bar x) (y_i - \bar y )}{(n-1)sd_x sd_y}$</p>

**Коэффициент детерминации** -- показатель, в какой степении изменчивость данных объясняется этой переменной

https://rpsychologist.com/correlation/

http://guessthecorrelation.com/

### Корреляционный тест

Гипотезы о наличии корреляции между переменными проверяются при помощи корреляционного теста. Это точно такой же статистический критерий, по сути -- ровно то же самое, что линейная регрессия с одной переменной. Корреляционный тест применяется, когда и ЗП, и НП являются количественными переменными либо выраженными в порядковкой шкале (но не номинативной). Для количественной шкалы обычно используется коэффициент корреляции Пирсена, для порядковой -- коэффициент корреляции Спирмена.

Корреляционный тест использует -- вы не поверите -- уже знакомое нам T-распределение Стьюдента!
(*то есть, нам надо запомнить вообще всего два распределения: T-распределение и F-распределение*)

Число степеней свободы вычисляется по формуле

<p align="center">$df = n - 2$, n -- число наблюдений </p>

Нулевая и альтернативная гипотезы для корреляционного теста:

<p align="center">$H_0$: $r_{xy} = 0$ </p>
<p align="center">$H_1$: $r_{xy} \neq 0$ </p>

Как и остальные критерии, он имеет допущения.

### Допущения для корреляционного теста

1. ЗП и НП измерены в количественной или порядковой шкале
2. Распределение НП по ЗП линейно -- то есть нет выборосов, нет картины нелинейной взаимосвязи или скоплений данных в разных местах.
3. (не обязательно) ЗП распределена нормально -- обсуждали эту проверку [здесь](#param_nonparam)


### Непараметрические аналоги

Если ЗП сильно отличается от нормального распределения, или выборка мала, или ЗП закодирована в порядковой шкале -- в коррялционном тесте используется коэффициент корреляции Спирмена вместо Пирсена, и этоо единственное различие.

### Расчет корреляционного теста

Проведем тест для следующей гипотезы.

> `Чем ниже студенты оценивают качество семейных отношений famrel, тем выше они отмечают частоту употребления алкоголя Walc `

```{r eval=TRUE, echo = FALSE, message = FALSE}
kable(students[1:10,]) %>% scroll_box(width = "100%") 
```

Пойдем также по алгоритму.

ЗП -- порядковая, НП -- порядковая. Наша гипотеза не о сравнении групп, об ассоциативной (корреляционной) связи.

Так как ЗП и НП порядковые, мне нужно использовать непараметрический аналог корреляциии Пирсона -- ранговую корреляцию Спирмена (либо порядковую логистическую регрессию (если я хочу, чтобы связь имела предсказательную силу)).

```{r, eval=TRUE}
cor.test(students$famrel, students$Walc, method = 'spearman')
```
Первый вариант визуализации -- мозаичный плот: размер плитки отражает частоту совпадения таких значений двух переменных. Указываем  НП как x=product(НП), и ЗП как fill = ЗП.

```{r, eval=TRUE}
library(ggmosaic)
students %>% 
  ggplot(aes()) + 
  geom_mosaic(aes(x = product(famrel), fill = Walc)) +
  scale_fill_viridis(discrete=TRUE) +
  theme_minimal() 
```

Другой вариант -- хитмеп, как в коррелограмме, где размеры фиксированные, а за частоту совпадений отвечает цвет.
```{r, eval=TRUE}
students %>% 
  ggplot(aes(x = as.factor(famrel), y = as.factor(Walc))) + 
  geom_bin2d() +
  scale_fill_viridis() +
  theme_minimal() +
  theme(panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank())
```
### Интерпретация результатов

Важно, что при очень большой выборке даже совсем слабая корреляционная связь будет достигать статистической с=значимости

<p align="center"> 
```{r eval=TRUE, echo = FALSE, message = FALSE, fig.align = 'center', out.width="80%"}
knitr::include_graphics("docs/images/corr_causation.png")
```
</p>

