[["probability.html", "4 Вероятность и случайные величины 4.1 Случайная величина 4.2 Дискретные СВ и статистическое определение вероятности 4.3 Столбчатая диаграмма и отличия от гистограммы 4.4 Непрерывные СВ и геометрическое определение вероятности 4.5 График плотности вероятности и гистограмма", " 4 Вероятность и случайные величины 4.1 Случайная величина Мы немного поговорили про переменные, они же – признаки исследуего нами объекта (рост, вес, пол, уровень образования и так далее). Поговорили, что чтобы измерить признак, нужно привести в соответствие какое-либо значение из шкалы. Теперь давайте посмотрим на математический смысл переменных и их значений. С математической точки зрения значения переменных являются случайными величинами. В теории вероятностей случайной величиной называется величина, которая в данный момент времени (момент измерения) может принимать только одно значение, которое нельзя предугадать точно (до измерения). Нам нужно замерить рост? Можем ли мы заранее сказать, сколько точно вплоть до микрометров он будет составлять? Если нет, значит, мы провели испытание (статистический термин единичного исследования или измерения), в ходе которого случайная величина рост приняла определенное значение (мы привели ей в соответствие какое-то значение из количественной шкалы). Говоря статистическим языком, наступило событие или явление “РОСТ = 178 см”. Нужно определить время реакции после выпитой кружки кофе? Все то же самое, время реакции – случайная величина. Результат прохождения опросника – случайная величина. Название ВУЗа, из которого пришел наш испытуемый – случайная величина. Это понятие нужно нам для того, чтобы мы могли считать вероятности наступления определенных событий, то есть наших измеренных переменных. Дело в том, что про вероятности случайных величин нам плюс-минус понятно и просто, а вот если величина перестает быть случайной, расчет вероятности становится сложнее. И мы пока рассматриваем только случайные величины. (Более подробный экскурс в случайный величины и теорию вероятностей можно получить в отличном учебнике Mathprofi http://mathprofi.ru/sluchainaya_velichina.html) ## Вероятность Что такое вероятность? По сути, вероятность – это численно выраженая возможность наступления того или иного события. Вероятность может рассматриваться как частота наступления уже свершившегося события: по тому, как часто оно происходило, можно оценить, какова вероятность его наступления в дальнейшем. Здесь начинается неожиданная развилка: в зависимости от того, как мы понимаем вероятность, приравниваем ли ее к частоте, статистика делится на байесовскую (bayesian) и частотную (фреквинтистскую, frequentist). Статистика, в которой мы заменяем вероятности частотами, а не высчитываем вероятность по сложной формуле, и в которой мы будем работать – частотная (https://en.wikipedia.org/wiki/Frequentist_inference). То есть говоря о вероятности, мы будем понимать ее исключительно так же, как и частоту, забываем про существование условной вероятности, формулу полной вероятности и других сложных концепций: если бы мы провели много раз одно и то же исследование, скажем, тысячу, и посмотрели, сколько раз в этом исследовании выпадает результат, который нас интересует, мы бы сказали, что вероятность наступления этого события – это сколько раз оно выпадало из тысячи. И будем руководствоваться только этим смыслом. Есть разные определения, в рамках статистики различают статистическое и геометрическое определение вероятностей. Можно углубиться на http://mathprofi.ru/sluchainaya_velichina.html. Разные определения вероятности используются в зависимости от того, с какими случайными величинами (СВ) мы работаем, различают два их типа: дискретные СВ непрерывные СВ 4.2 Дискретные СВ и статистическое определение вероятности Самая часто используемая в теории вероятностей модель – бросание обычного шестигранного игрального кубика. Кубик отличает то, что всего возможно наступление 6 событий (не будем рассматривать, что кубик смещенный или какой-то неправильный). То есть область допустимых значений или область определения для случайной величины “бросок кубика” это 6 значений: \\(D \\in \\{1, 2, 3, 4, 5, 6\\}\\) Величина, область значений которой состоит из конечного числа натуральных чисел (1; 2; 3; 4; 5…), называется дискретной. Для определения вероятности дискретной величны воспользуемся ее статистическим определением, не углубляясь в статистические термины: если при проведении испытания возможны \\(n\\) равновероятных исходов значений случайной величины \\(A\\), при этом в \\(m\\) из них случается интересующее нас конкретное событие \\(A_{i}\\),то вероятность наступления события \\(P(A_{i}) = \\frac{m}{n}\\) Бросание игрального кубика – это испытание, выпадение одной из граней – исход, а выпадение конкретно шестерки – событие. Обозначим выпадние грани в результате бросания кубика буквой \\(K\\). Чему равна вероятность выпадения каждой грани \\(K_{1}\\), \\(K_{2}\\), \\(K_{3}\\), \\(K_{4}\\), \\(K_{5}\\), \\(K_{6}\\)? По статистическому определению вероятности: возможных исходов всего – 6, интересующее нас событие случается в одном случае из 6, то есть: \\(P(K_{1})\\) = \\(P(K_{2})\\) = \\(P(K_{3})\\) = \\(P(K_{4})\\) = \\(P(K_{5})\\) = \\(P(K_{6})\\) = \\(\\frac{1}{6}\\) Важно, что все события равновероятны. Если бы мы жили в мире с кубиками со смещенным центром тяжести, выпадние граней не было бы равновероятным. А чему равна полная вероятность? Как можно вывести это математически из вероятностей наступления событий в бросании игрального кубика? \\(P(K_{1})\\) + \\(P(K_{2})\\) + \\(P(K_{3})\\) + \\(P(K_{4})\\) + \\(P(K_{5})\\) + \\(P(K_{6})\\) = \\(1\\) Единичные события нас мало интересуют (предмет изучения теории вероятностей – массовые события), поэтому давайте представим, что мы бросили кубик несколько раз. Например, 20. library(tidyverse) library(TeachingDemos) rolls &lt;- dice(20,1) t(rolls) ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] [,13] [,14] ## Red 1 5 6 5 4 4 2 3 6 4 4 2 1 1 ## [,15] [,16] [,17] [,18] [,19] [,20] ## Red 5 5 5 6 2 5 4.3 Столбчатая диаграмма и отличия от гистограммы Построим таблицу частот выпадения каждой грани table(rolls) ## Red ## 1 2 3 4 5 6 ## 3 3 1 4 6 3 prop.table(table(rolls)) ## Red ## 1 2 3 4 5 6 ## 0.15 0.15 0.05 0.20 0.30 0.15 Можем наглядно посмотреть это на столбчатой (или столбиковой) диаграмме – графике, отображающем частоты встречаемости событий дискретной переменной. rolls %&gt;% ggplot(aes(x=Red)) + geom_bar(bins = 6, binwidth = 1) + theme_minimal() ## Warning in geom_bar(bins = 6, binwidth = 1): Ignoring unknown parameters: ## `bins` and `binwidth` Сразу введем понятие гистограммы – это похожий на столбчатую диаграмму график, но, в отличие от столбчатой диаграммы, он используется исключительно для количественных данных, и мы можем регулировать ширину столбика по оси \\(x\\), задавать, сколько значений переменной х в него войдет (например,не только грань 1, но и грани 1 + 2), и высотка столбика будут пересчитана в зависимости от этого количества. В столбиковой диаграмме мы так сделать не можем, по оси \\(x\\) всегда только одно значение, каждый столбик соотносится с конкретным значением переменной. rolls %&gt;% ggplot(aes(x=Red)) + geom_histogram(bins = 6, binwidth = 1) + theme_minimal() 4.4 Непрерывные СВ и геометрическое определение вероятности С непрерывными величинами чуть посложнее, поэтому нам понадобится геометрическое определение вероятности. Построим отрезок на оси \\(x\\) от 0 до 1. Допустим, мы проводим испытание, где бесконечно малым курсором проводим по этому отрезку. Остановку курсора в какой-то точке обозначим за \\(L\\). Какова вероятность, что курсор остановится в точке с координатами \\(x=0.4857856\\)? Сколько точек лежат в этом отрезке? Вспоминаем, что точка – бесконечно малая величина, поэтому на этом отрезке лежит бесконечное число точек. Область допустимых значений или область определения для случайной величины “остановка курсора в точке” – бесконечное число значений в диапазоне \\(D \\in [0;1]\\) Величина, область допустиимых значений которой состоит из бесконечного числа значений на каком-либо ненеулевом промежутке, которые невозможно посчитать, называется непрерывной. Попробуем воспользоваться статистическим определением вероятности: \\(P(L_{.4857856}) = \\frac{1}{множество всех точек на отрезке} = \\frac{1}{\\infty} \\sim 0\\) В пределе это число равно 0. Получается, что мы не можем посчитать математически (статистически), и приходится прибегать к геометрическому определению. 4.5 График плотности вероятности и гистограмма Построим таблицу и график частот для значений из отрезка. Для это сгенерируем набор из 10 случайных чисел в диапазоне [0;1]. set.seed(42) line_sample &lt;- runif(10, min=0, max=1) line_sample ## [1] 0.9148060 0.9370754 0.2861395 0.8304476 0.6417455 0.5190959 0.7365883 ## [8] 0.1346666 0.6569923 0.7050648 table(line_sample) ## line_sample ## 0.13466659723781 0.286139534786344 0.519095949130133 0.641745518893003 ## 1 1 1 1 ## 0.656992290401831 0.705064784036949 0.736588314641267 0.830447626067325 ## 1 1 1 1 ## 0.914806043496355 0.937075413297862 ## 1 1 prop.table(table(line_sample)) ## line_sample ## 0.13466659723781 0.286139534786344 0.519095949130133 0.641745518893003 ## 0.1 0.1 0.1 0.1 ## 0.656992290401831 0.705064784036949 0.736588314641267 0.830447626067325 ## 0.1 0.1 0.1 0.1 ## 0.914806043496355 0.937075413297862 ## 0.1 0.1 Видим, что все значения встретились только один раз. Построим график. Можем построить гистограмму для этих значений: as_tibble(line_sample) %&gt;% ggplot(aes(x=value)) + geom_histogram(bins = 10) + theme_minimal() Получается довольно странно: мы видели, что частота встречаемости разных значений – всегда была единичка, а на гистограмме кажется по-другому. Так происходит, потому что мы взяли только 10 очень конкретных крошечных значений из непрерывной величины, и нам попались какие-то значения – рядом друг с другом, и столбики для их частот “слиплись” в один большой столбик, и частота получилась не 1, а 2. А какие-то значения попались далеко друг от друга, поэтому их столбики слиплись не друг с другом, а с более близкими к ним столбиками, и на месте частоты для этого значения образовалась дырка. Такой график для непрерывной величины не очень верный: чтобы стобики не “слипались” и не обманывали нас визуально, будто где-то в значениях есть дыра, для непрерывных величин мы будем использовать другой график – график плотности вероятности (probability density) as_tibble(line_sample) %&gt;% ggplot(aes(x=value)) + geom_density() + theme_minimal() Он тоже показывает так, будто какие-то значения более частые, какие-то менее – но ситуация уже гораздо лучше. Здесь мы сгенерировали 10 значений, а если нам вдруг нужно визуализировать все возможные значения из отрезка [0;1], а х бесконечность? Тогда гистограмма вообще потеряет всякий смысл, так как разбивает все значения на столбики из конечных интервалов, а вот непрерывная линию будет подходящей – в непрерывной линии бесконечное число значений! То есть выходит следующая логика: для визуализации категориальных данных (номинативных и порядковых – количественных дискретных) используют столбчатую диаграмму (например, количество выбравших в опроснике ответ “1”, “2”, “3”; средняя температура по месяцам) для визуализации непрерывных величин на маленьком диапазоне, где хорошо выделяются интервалы, иногда для визуализации количественных дискретных (порядковых) данных – используют гистограмму; для визуализации непрерывных величин (шкала отношений, относительная шкала) – график плотности вероятности. Почему плотности вероятности, а не самой вероятности? Потому что как мы вывели выше, если бы мы считали точно именно вероятность, она бы стремилась к нулю. А засчет того, что это именно плотность, буквально, “тут побольше значений”, “тут поменьше значений” – получается осмысленный график. То есть, простыми словами, плотность вероятности – характер распределения вероятностей в самом значении и его окрестности. Если в интервале [0.25;0.35] оказалось (чисто случайно) мало значений, а в интервале [0.58;0.65] оказалось побольше – то на графике плотности вероятности мы увидим различия в вероятности для этих интервалов, хотя вероятность встретить каждое конкретное очень точно заданное число (например, 0.4857856) стремится к 0. Мы не будем рассматривать математически смысл плотности вероятности, но функция плотности вероятности является производной от функции самой вероятности. Попробуем сгенерировать этот же график для 500 и 10 000 точек и посмотреть, к чему будет стремиться график плотности вероятности в случае, когда мы случайно генерируем множество значений, все из которых равновероятны? line_sample_500 &lt;- runif(500, min=0, max=1) as_tibble(line_sample_500) %&gt;% ggplot(aes(x=value)) + geom_density() + theme_minimal() 10000 точек из этого же диапазона line_sample_10000 &lt;- runif(10000, min=0, max=1) as_tibble(line_sample_10000) %&gt;% ggplot(aes(x=value)) + geom_density() + theme_minimal() Итак, запомнили, что мы рассматриваем признаки (переменные) как случайные величины, они могут быть дисркетные и непрерывные, и их вероятности описываются определенными законами распределения. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
