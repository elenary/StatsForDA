[["stats_criteria_linear.html", "11 Проверка линейной свзяи 11.1 Корреляционный анализ 11.2 Линейный регрессионный анализ", " 11 Проверка линейной свзяи До этого мы рассматривали виды статистического анализа, когда нужно было сравнить средние значения в нескольких группах. Зависимая переменная всегда была количественная (ее среднее значение по группам мы и сравнивали), а независимая – категориальная, принимала конечное число значений, и каждое ее значение – отдельный уровень НП, отдельная группа. Теперь мы переходим к статистическим критериям, которые используются, когда обе переменные, и ЗП, и НП – количественные. 11.1 Корреляционный анализ Корреляция – это связь между переменными. Несмотря на то, что она называется так же, как и один из двух видов связи между переменными, корреляционную связь можно выявить с помощью в целом любых видов анализа – ведь когда мы получаем результаты статистических критериев, мы понимем только, что две переменные связаны (или нет), но не можем сделать вывод о том, причинно-следственная это связь или корреляционная. Здесь речь пойдет именно про корреляционный анализ – специальный вид анализа для определения значимости линейной связи только между двумя количественными или порядковыми переменными. Чтобы вывести формулу и смысл корреляции, познакомимся с понятием ковариации. Ко-вариация (co-variance) – это мера со-изменчивости данных, показатель того, как наблюдения по двум количественным переменным меняются друг относительно друга. Картинка отсюда \\(\\text{cov}(x,y)=\\frac{\\sum_{i=1}^n (x_i - \\bar x) (y_i - \\bar y )}{n-1}\\) Шок-контент: попробуйте посчитать ковариацию переменной самой с собой и посмотрите на получившуюся формулу: ничего не напоминает? Ковариация самой с собой \\(\\text{cov}(x,x)=\\frac{\\sum_{i=1}^n (x_i - \\bar x) (x_i - \\bar x )}{n-1} = \\frac{\\sum_{i=1}^n (x_i - \\bar x )^2}{n-1}\\) И это дисперсия! Коэффициент корреляции – это показатель силы и направления связи между переменными. За силу связи отвечает модуль числа, за направление – знак корреляции. По сути, это ковариация переменных, но взвешенная на стандартные отклонения этих переменных. Это сделано для того, чтобы стандартизовать коэффициент, уйти от абсолютных значений к относительным и расположить этот коэффицент в границах [-1;1]. Для коэффициента корреляции Пирсона (корреляции двух количественных переменных): \\(\\text{corr}(x,y) = r_{xy} = \\frac{\\text{cov(x, y)}}{sd_x sd_y} = \\frac{\\sum_{i=1}^n (x_i - \\bar x) (y_i - \\bar y )}{(n-1)sd_x sd_y}\\) Коэффициент детерминации – показатель, в какой степении изменчивость данных объясняется этой выбранной независимой переменной. В случае, если у нас только одна НП, то коэффициент детерминации – практически то же самое, что и корреляция, только взятая в квадрат: \\(R^2 = r_{xy}^2 = \\frac{\\text{cov(x, y)}}{sd_x sd_y} = \\frac{\\sum_{i=1}^n (x_i - \\bar x) (y_i - \\bar y )}{(n-1)sd_x sd_y}\\) https://rpsychologist.com/correlation/ http://guessthecorrelation.com/ 11.1.1 Корреляционный тест Гипотезы о наличии линейной связи между переменными проверяются при помощи корреляционного теста. Это точно такой же статистический критерий, как и те, что мы уже разобрали. По сути – ровно то же самое, что линейная регрессия с одной переменной. Корреляционный тест применяется, когда и ЗП, и НП являются количественными переменными либо выраженными в порядковкой шкале (но не номинативной). Для количественной шкалы обычно используется коэффициент корреляции Пирсона, для порядковой или для количественной переменной с малым числом наблюдений – коэффициент корреляции Спирмена. Корреляционный тест использует – вы не поверите – уже знакомое нам T-распределение Стьюдента! (то есть, нам надо запомнить вообще всего два распределения: T-распределение и F-распределение) Число степеней свободы вычисляется по формуле \\(df = n - 2\\), n – число наблюдений Нулевая и альтернативная гипотезы для корреляционного теста: \\(H_0\\): \\(r_{xy} = 0\\) \\(H_1\\): \\(r_{xy} \\neq 0\\) Как и остальные критерии, он имеет допущения. 11.1.2 Допущения для корреляционного теста ЗП и НП измерены в количественной или порядковой шкале Распределение НП по ЗП линейно – то есть нет выборосов, нет картины нелинейной взаимосвязи или скоплений данных в разных местах. (не обязательно) ЗП распределена нормально – обсуждали эту проверку здесь Примеры, как может выглядеть нелинейное распределение: 11.1.3 Непараметрические аналоги Если ЗП сильно отличается от нормального распределения, или выборка мала, или ЗП закодирована в порядковой шкале – в коррялционном тесте используется коэффициент корреляции Спирмена вместо Пирсена, и это единственное различие. Есть еще тау-Кендалла, это почти то же самое, что и корреляция Спирмена, но мы не будем ее рассматривать, так как она применяется крайне редко. Из статьи в википедии про корреляцию 11.1.4 Расчет корреляционного теста Проведем тест для следующей гипотезы. Чем ниже студенты оценивают качество семейных отношений famrel, тем выше они отмечают частоту употребления алкоголя Walc student school sex age address famsize Pstatus Medu Fedu Mjob Fjob reason guardian traveltime studytime failures schoolsup famsup paid_mat activities nursery higher internet romantic famrel freetime goout Dalc Walc health absences_mat G1_mat G2_mat G3_mat paid_por absences_por G1_por G2_por G3_por G_mat G_por absences_mat_groups absences_por_groups id1 GP F 18 U GT3 A 4 4 at_home teacher course mother 2 2 0 yes no no no yes yes no no 4 3 4 1 1 3 6 5 6 6 no 4 0 11 11 5.666667 7.333333 middle less id2 GP F 17 U GT3 T 1 1 at_home other course father 1 2 0 no yes no no no yes yes no 5 3 3 1 1 3 4 5 5 6 no 2 9 11 11 5.333333 10.333333 less less id4 GP F 15 U GT3 T 4 2 health services home mother 1 3 0 no yes yes yes yes yes yes yes 3 2 2 1 1 5 2 15 14 15 no 0 14 14 14 14.666667 14.000000 less less id5 GP F 16 U GT3 T 3 3 other other home father 1 2 0 no yes yes no yes yes no no 4 3 2 1 2 5 4 6 10 10 no 0 11 13 13 8.666667 12.333333 less less id6 GP M 16 U LE3 T 4 3 services other reputation mother 1 2 0 no yes yes yes yes yes yes no 5 4 2 1 2 5 10 15 15 15 no 6 12 12 13 15.000000 12.333333 middle middle id7 GP M 16 U LE3 T 2 2 other other home mother 1 2 0 no no no no yes yes yes no 4 4 4 1 1 3 0 12 12 11 no 0 13 12 13 11.666667 12.666667 less less id8 GP F 17 U GT3 A 4 4 other teacher home mother 2 2 0 yes yes no no yes yes no no 4 1 4 1 1 1 6 6 5 6 no 2 10 13 13 5.666667 12.000000 middle less id9 GP M 15 U LE3 A 3 2 services other home mother 1 2 0 no yes yes no yes yes yes no 4 2 2 1 1 1 0 16 18 19 no 0 15 16 17 17.666667 16.000000 less less id10 GP M 15 U GT3 T 3 4 other other home mother 1 2 0 no yes yes yes yes yes yes no 5 5 1 1 1 5 0 14 15 15 no 0 12 12 13 14.666667 12.333333 less less id11 GP F 15 U GT3 T 4 4 teacher health reputation mother 1 2 0 no yes yes no yes yes yes no 3 3 3 1 2 2 0 10 8 9 no 2 14 14 14 9.000000 14.000000 less less Пойдем также по алгоритму. ЗП – порядковая, НП – порядковая. Наша гипотеза не о сравнении групп между собой, а то, что эти переменные коррелируют, между ними есть линейная связь. Так как ЗП и НП порядковые, мне нужно использовать непараметрический аналог корреляциии Пирсона – ранговую корреляцию Спирмена (либо порядковую логистическую регрессию (если я хочу, чтобы связь имела предсказательную силу), но об этом не в этот раз). cor.test(students$famrel, students$Walc, method = &#39;spearman&#39;) ## Warning in cor.test.default(students$famrel, students$Walc, method = ## &quot;spearman&quot;): Cannot compute exact p-value with ties ## ## Spearman&#39;s rank correlation rho ## ## data: students$famrel and students$Walc ## S = 6173557, p-value = 0.0196 ## alternative hypothesis: true rho is not equal to 0 ## sample estimates: ## rho ## -0.130423 Первый вариант визуализации – мозаичный плот: размер плитки отражает частоту совпадения таких значений двух переменных. Указываем НП как x=product(НП), и ЗП как fill = ЗП. library(ggmosaic) students %&gt;% ggplot(aes()) + geom_mosaic(aes(x = product(famrel), fill = Walc)) + scale_fill_viridis(discrete=TRUE) + theme_minimal() Другой вариант – хитмеп, как в коррелограмме, где размеры фиксированные, а за частоту совпадений отвечает цвет. students %&gt;% ggplot(aes(x = as.factor(famrel), y = as.factor(Walc))) + geom_bin2d() + scale_fill_viridis() + theme_minimal() + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank()) ### Интерпретация результатов Важно, что при очень большой выборке даже совсем слабая корреляционная связь будет достигать статистической значимости 11.1.5 Корреляционные матрицы Часто встречется анализ корреляционных матриц – когда корреляции вычисляются попарно для каждой матрицы переменных. Это можно встретить, например, при корреляции опросников: допустим, есть опросник О1 и О2. В опроснике О1 есть субшкалы С11, С12, С13, С14, С15, а в О2 соответственно – С21, С22, С23, С24, С25. Тогда мы можем построить корреляционную матрицу для субшкал этих опросников. 11.2 Линейный регрессионный анализ Линейная регрессия – это ровно та же известная нам ANOVA, только если заменить категориальные НП на количественные! А еще линейная регрессия – это то же самое, что корреляция, только для нескольких НП. Совмещая ANOVA и корреляционный анализ, получили линейный регрессионный! Регрессионный анализ – довольная мощная штука, потому что здесь мы впервые начинаем говорить о предсказательной функции анализа. Выходит, что регрессионный анализ может применяться: Для проверки гипотез о наличии линейной связи между количественными или порядковыми переменными Для предсказания значений ЗП за пределами имеющихся данных 11.2.1 Коэффициенты регрессии Уравнение регрессионной прямой: \\(y = b_o + b_1x\\) Естьнесколько формул для вычисления коэффициентов линейной регрессии, но все они взаимовычисляемы. Вручную считать мы их не будем, поэтому что важно запомнить: Коэффициент \\(b_1\\) отвечает на наклон прямой (slope) Коэффициент \\(b_0\\) отвечает за смещение прямой вдоль оси y (intercept) При подсчете коэффициентов первым высчитывается \\(b_1\\), и он зависит от величины вариативности данных по переменным x и y (стандартных отклонений или дисперсий) и в случае равной вариативности является коэффициентом корреляции \\(r_{xy}\\) \\(b_{1_{xy}} = \\frac{sd_y}{sd_x} r_{xy}\\) \\(b_o = \\bar y -b_{1_{xy}}\\bar x\\) Коэффициенты считаются таким образом, чтобы сумма квадратов остатков была минимальна. Это называется методом наименьших квадратов. 11.2.2 Регрессионный анализ (тестирование коэффициентов регрессии) Нулевая и альтернативная гипотезы: \\(H_0\\): \\(b_{1_{xy}} = 0\\) \\(H_1\\): \\(b_{1_{xy}} \\neq 0\\) 11.2.3 Допущения для регрессионного анализа (ЗП и НП измерены в количественной или порядковой шкале) Распределение НП по ЗП линейно – то есть нет выборосов, нет картины нелинейной взаимосвязи или скоплений данных в разных местах. Остатки (residuals) распределены нормально – все то же самое, как здесь, только для остатков Остатки (residuals) варьируются примерно одинаково вдоль всей прямой (гомоскедастичность) https://gallery.shinyapps.io/slr_diag/ 11.2.4 Расчет регрессионного анализа model_Gmat &lt;- lm(students$G_mat ~ students$absences_mat) summary(model_Gmat) ## ## Call: ## lm(formula = students$G_mat ~ students$absences_mat) ## ## Residuals: ## Min 1Q Median 3Q Max ## -9.3130 -2.1013 0.0045 2.4727 8.1262 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 11.31298 0.24196 46.76 &lt;2e-16 *** ## students$absences_mat -0.02645 0.02544 -1.04 0.299 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 3.559 on 318 degrees of freedom ## Multiple R-squared: 0.00339, Adjusted R-squared: 0.0002563 ## F-statistic: 1.082 on 1 and 318 DF, p-value: 0.2991 "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
